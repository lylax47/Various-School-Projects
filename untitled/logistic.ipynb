{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import sklearn.metrics as mt\n",
    "import json\n",
    "import regex as re\n",
    "import multiprocessing\n",
    "import time\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from pymystem3 import Mystem\n",
    "from sklearn import linear_model\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pos_bi(text, m):\n",
    "    pos_tags = []\n",
    "    sents = sent_tokenize(text)\n",
    "    for sent in sents:\n",
    "        sent_an = []\n",
    "        analy = m.analyze(sent)\n",
    "        for x in analy:\n",
    "            try:\n",
    "                if 'analysis' in x.keys():\n",
    "                    tag = x['analysis'][0]['gr']\n",
    "                    sent_an.append(re.sub(r'[=|,].*', '', tag).lower())\n",
    "            except IndexError:\n",
    "                pass\n",
    "        pos_tags.append(sent_an)\n",
    "    return pos_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_corp(texts, m):\n",
    "    text_all = []\n",
    "    for text in texts:\n",
    "        text_all.append(pos_bi(text, m))\n",
    "    return text_all\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calc_bigrams(corp):\n",
    "    bis = defaultdict(int)\n",
    "    uni = defaultdict(int)\n",
    "    bis_text = defaultdict(int)\n",
    "    pmis = defaultdict(float)\n",
    "    total = 0\n",
    "    for text in corp: #calc bigram totals, text totals, and total words\n",
    "        text_c = []\n",
    "        for sent in text:\n",
    "            total += len(sent)\n",
    "            for x in range(len(sent)):\n",
    "                uni[sent[x]] += 1\n",
    "                if x < len(sent)-1:\n",
    "                    bi = \"{0}:{1}\".format(sent[x], sent[x+1])\n",
    "                    bis[bi] += 1\n",
    "                    if bi not in text_c:\n",
    "                        text_c.append(bi)\n",
    "        for n in text_c:\n",
    "            bis_text[n] += 1\n",
    "    for k,v in bis_text.items(): #remove if in less than 75% of texts\n",
    "        if v/226 < 0.75:\n",
    "            del bis[k]\n",
    "    for k,v in bis.items():    #calc pmi of pos pairs\n",
    "        pos1, pos2 = k.split(':')\n",
    "        p1v = uni[pos1]\n",
    "        p2v = uni[pos2]\n",
    "        ptg = v\n",
    "        pmi = math.log((ptg/p1v*p2v), 2)\n",
    "        pmis[k] = pmi\n",
    "    return pmis, total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pmi_count_over_total(m, bi, pmi, text):\n",
    "    poses = pos_bi(text, m)\n",
    "    pos1, pos2 = bi.split(':')\n",
    "    count = 0\n",
    "    total = len(poses)\n",
    "    for sent in poses:\n",
    "        for x in range(len(sent)-1):\n",
    "            if sent[x] == pos1 and sent[x+1] == pos2:\n",
    "                count +=1\n",
    "    stat = count/total\n",
    "    return stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def imp (filenames, root):\n",
    "    sheets =[]\n",
    "    for f in filenames:\n",
    "        if f != 'sex.csv' and f != 'new_info.csv':\n",
    "            df = pd.read_csv(os.path.join(root, f), index_col=0)\n",
    "            sheets.append(df)\n",
    "        elif f == 'sex.csv':\n",
    "            df2 = pd.read_csv(os.path.join(root, f))\n",
    "        else:\n",
    "            df3 = pd.read_csv(os.path.join(root, f))\n",
    "    comb = pd.concat(sheets, axis=1)\n",
    "    new_vec = list((1,0)*113)\n",
    "    comb['Truth'] = new_vec\n",
    "    comb['Sex'] = ''\n",
    "    comb['Avg_sent'], comb['TTR'], comb['Avg_word'], comb['Hapax'], comb['Yules'] = 0,0,0,0,0\n",
    "    m = Mystem()\n",
    "    lie_corp = df3[df3['Truth'] == 1]\n",
    "    true_corp = df3[df3['Truth'] == 0]\n",
    "    lies = create_corp(lie_corp['Text'], m)\n",
    "    truths = create_corp(true_corp['Text'], m)\n",
    "    corp = lies + truths\n",
    "    pmis, total = calc_bigrams(corp)\n",
    "    for num in df2['ID']:\n",
    "        num2 = num - 1\n",
    "        comb.loc['{0}Л.docx'.format(num), 'Sex'] = df2.ix[num2, 'Пол']\n",
    "        comb.loc['{0}П.docx'.format(num), 'Sex'] = df2.ix[num2, 'Пол']\n",
    "    for index, row in df3.iterrows():\n",
    "        r = int(row['ID'])\n",
    "        text = str(row['Text'])\n",
    "        if row['Truth'] == 1:\n",
    "            comb.loc['{0}Л.docx'.format(r), ['Avg_sent']] = row['Avg_sent']\n",
    "            comb.loc['{0}Л.docx'.format(r), ['TTR']] = row['TTR']\n",
    "            comb.loc['{0}Л.docx'.format(r), ['Avg_word']] = row['Avg_word']\n",
    "            comb.loc['{0}Л.docx'.format(r), ['Hapax']] = row['Hapax']\n",
    "            comb.loc['{0}Л.docx'.format(r), ['Yules']] = row['Yules']\n",
    "            for k,v in pmis.items():\n",
    "                comb[k] = 0\n",
    "                comb.loc['{0}Л.docx'.format(r), [k]] = pmi_count_over_total(m, k, v, row['Text'])\n",
    "                \n",
    "        else:\n",
    "            comb.loc['{0}П.docx'.format(r), ['Avg_sent']] = row['Avg_sent']\n",
    "            comb.loc['{0}П.docx'.format(r), ['TTR']] = row['TTR']\n",
    "            comb.loc['{0}П.docx'.format(r), ['Avg_word']] = row['Avg_word']\n",
    "            comb.loc['{0}П.docx'.format(r), ['Hapax']] = row['Hapax']\n",
    "            comb.loc['{0}П.docx'.format(r), ['Yules']] = row['Yules']\n",
    "            for k,v in pmis.items():\n",
    "                comb[k] = 0\n",
    "                comb.loc['{0}Л.docx'.format(r), [k]] = pmi_count_over_total(m, k, v, row['Text'])\n",
    "    return comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_reg(df, labs):\n",
    "    train = df.sample(frac=0.7, random_state=1)\n",
    "    test = df.loc[~df.index.isin(train.index)]\n",
    "    xtrain = train[labs]\n",
    "    xtest = test[labs]\n",
    "    ytrain = train['Truth']\n",
    "    ytest = test['Truth']\n",
    "    reg = linear_model.LogisticRegressionCV()\n",
    "    reg.fit(xtrain,ytrain)\n",
    "    preds = reg.predict(xtest)\n",
    "    print(reg.coef_)\n",
    "    print(mean_squared_error(preds, ytest))\n",
    "    print(reg.score(xtest, ytest))\n",
    "    print(mt.r2_score(ytest, preds))\n",
    "    print(mt.classification_report(ytest, preds, target_names=['Truth', 'Lie']))\n",
    "    print(mt.accuracy_score(ytest, preds))\n",
    "    print(mt.confusion_matrix(ytest, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_sex(df, labs):\n",
    "    mal = df[df['Sex'] == 'муж.']\n",
    "    fem = df[df['Sex'] == 'жен.']\n",
    "\n",
    "    print(len(mal))\n",
    "    print(len(fem))\n",
    "\n",
    "    train_mal = mal.sample(frac=0.6, random_state=1)\n",
    "    train_fem = fem.sample(frac=0.6, random_state=1)\n",
    "\n",
    "    test_mal = df.loc[~mal.index.isin(train_mal.index)]\n",
    "    test_fem = df.loc[~fem.index.isin(train_fem.index)]\n",
    "\n",
    "    xtrain_mal = train_mal[labs]\n",
    "    xtrain_fem = train_fem[labs]\n",
    "    xtest_mal = test_mal[labs]\n",
    "    xtest_fem = test_fem[labs]\n",
    "\n",
    "    ytrain_mal = train_mal['Truth']\n",
    "    ytrain_fem = train_fem['Truth']\n",
    "    ytest_mal = test_mal['Truth']\n",
    "    ytest_fem = test_fem['Truth']\n",
    "\n",
    "    reg_mal = linear_model.LogisticRegressionCV()\n",
    "    reg_fem = linear_model.LogisticRegressionCV()\n",
    "\n",
    "    reg_mal.fit(xtrain_mal, ytrain_mal)\n",
    "    preds_mal = reg_mal.predict(xtest_mal)\n",
    "\n",
    "    reg_fem.fit(xtrain_fem, ytrain_fem)\n",
    "    preds_fem = reg_fem.predict(xtest_fem)\n",
    "\n",
    "    print(reg_mal.coef_)\n",
    "    print(mean_squared_error(preds_mal, ytest_mal))\n",
    "    print(reg_mal.score(xtest_mal, ytest_mal))\n",
    "    print(mt.r2_score(ytest_mal, preds_mal))\n",
    "    print(mt.classification_report(ytest_mal, preds_mal, target_names=['Truth', 'Lie']))\n",
    "    print(mt.confusion_matrix(ytest_mal, preds_mal))\n",
    "\n",
    "    print(reg_fem.coef_)\n",
    "    print(mean_squared_error(preds_fem, ytest_fem))\n",
    "    print(reg_fem.score(xtest_fem, ytest_fem))\n",
    "    print(mt.r2_score(ytest_fem, preds_fem))\n",
    "    print(mt.classification_report(ytest_fem, preds_fem, target_names=['Truth', 'Lie']))\n",
    "    print(mt.confusion_matrix(ytest_fem, preds_fem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for root, dirs, files in os.walk('russian_deception_bank/tables/'):\n",
    "    f = files\n",
    "results = imp(f, root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results.to_csv('allinfo.csv', delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['и', 'Личноеместоимение', 'вербальные', 'Предлог', 'Союз', 'Когнитив', 'Включение', 'AllPunc', 'мест.-сущ.', 'добавление', 'Avg_sent', 'TTR', 'Avg_word', 'Hapax', 'Yules', 'pr:s', 'conj:spro', 's:v', 'adv:v', 'spro:v', 'a:s', 'v:spro', 'pr:spro', 'pr:apro', 's:spro', 'v:s', 'v:adv', 's:s', 'v:pr', 'apro:s', 's:pr', 'v:conj', 'v:v', 'part:v', 'conj:v', 's:conj']\n",
      "[[  1.25372305e-03   6.26983322e-04   1.84935688e-03   1.92192455e-04\n",
      "    2.21533709e-03   3.04824868e-03   2.22530755e-03  -3.54849318e-03\n",
      "    7.06015044e-04   1.25141845e-03   1.21816268e-03  -5.54807004e-06\n",
      "    1.53655042e-05   1.22745869e-06  -7.92029513e-05   5.32682999e-05\n",
      "    4.09756153e-06   1.63902461e-05   1.22926846e-05   6.55609845e-05\n",
      "    3.27804922e-05   1.22926846e-05   1.63902461e-05   8.19512306e-06\n",
      "    2.45853692e-05   2.04878077e-05   4.09756153e-06   1.63902461e-05\n",
      "    4.09756153e-05   3.68780538e-05   4.09756153e-05   2.45853692e-05\n",
      "    4.09756153e-05   1.22926846e-05   8.19512306e-06   1.63902461e-05]]\n",
      "0.455882352941\n",
      "0.544117647059\n",
      "-0.825108225108\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      Truth       0.61      0.31      0.42        35\n",
      "        Lie       0.52      0.79      0.63        33\n",
      "\n",
      "avg / total       0.57      0.54      0.52        68\n",
      "\n",
      "0.544117647059\n",
      "[[11 24]\n",
      " [ 7 26]]\n",
      "92\n",
      "134\n",
      "[[  7.59483127e-04   1.15843803e-03   1.50666909e-03   1.47126485e-04\n",
      "   -1.73178946e-04   1.48989786e-06   1.20997153e-03  -2.75047192e-03\n",
      "    1.68416125e-04   7.77851484e-04  -2.04283653e-04   7.99541139e-06\n",
      "    5.84049115e-05   1.26954416e-05   1.65628617e-04   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00]]\n",
      "0.432432432432\n",
      "0.567567567568\n",
      "-0.730994152047\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      Truth       0.80      0.21      0.33        19\n",
      "        Lie       0.53      0.94      0.68        18\n",
      "\n",
      "avg / total       0.67      0.57      0.50        37\n",
      "\n",
      "[[ 4 15]\n",
      " [ 1 17]]\n",
      "[[  4.94166169e-04   6.11067307e-04   6.23600617e-04  -4.68286318e-04\n",
      "    1.33729573e-03   6.11055933e-04   3.06537576e-04  -4.41360487e-04\n",
      "    8.92496715e-04   9.19378995e-05   3.88245332e-03  -9.64057740e-06\n",
      "   -1.18097949e-04   2.09015888e-06  -8.32382298e-04   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00]]\n",
      "0.462962962963\n",
      "0.537037037037\n",
      "-0.851851851852\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      Truth       0.53      0.59      0.56        27\n",
      "        Lie       0.54      0.48      0.51        27\n",
      "\n",
      "avg / total       0.54      0.54      0.54        54\n",
      "\n",
      "[[16 11]\n",
      " [14 13]]\n"
     ]
    }
   ],
   "source": [
    "a = list(results)\n",
    "a = list(filter(lambda x: x != 'Truth' and x != 'Sex' and x != 'Segment', a))\n",
    "print(a)\n",
    "print(results)\n",
    "log_reg(results, a)\n",
    "log_sex(results, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
